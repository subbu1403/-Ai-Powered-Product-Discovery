{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define paths\n",
        "MODEL_NAME = \"gpt2-medium\"\n",
        "TOKENIZER = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "CONFIG = GPT2Config.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Ensure PAD token exists\n",
        "TOKENIZER.pad_token = TOKENIZER.eos_token\n",
        "\n",
        "# Load sentence transformer model for similarity comparison\n",
        "SIMILARITY_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "class ProductDescriptionDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=128):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        product_name = str(self.data.iloc[idx].get(\"product_name\", \"Unknown\"))\n",
        "        category = str(self.data.iloc[idx].get(\"category\", \"Unknown\"))\n",
        "        price = str(self.data.iloc[idx].get(\"discounted_price\", \"Unknown\"))\n",
        "        link = str(self.data.iloc[idx].get(\"product_link\", \"Unknown\"))\n",
        "        about_product_review = str(self.data.iloc[idx].get(\"review_content\", \"No Review\"))\n",
        "\n",
        "        input_text = f\"{product_name}. Category: {category}. Price: {price}. Link: {link}. About Product Review: {about_product_review}\"\n",
        "\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            input_text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return encoded[\"input_ids\"].squeeze(0), encoded[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "\n",
        "def recommend_products(user_description, dataset, similarity_model, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommend top N products based on the user's product description.\n",
        "    \"\"\"\n",
        "    # Compute embedding for user input\n",
        "    user_embedding = similarity_model.encode(user_description, convert_to_tensor=True)\n",
        "\n",
        "    product_texts = []\n",
        "    product_details = []\n",
        "\n",
        "    # Extract product details for similarity matching\n",
        "    for idx in range(len(dataset.data)):\n",
        "        product_name = dataset.data.iloc[idx][\"product_name\"]\n",
        "        category = dataset.data.iloc[idx][\"category\"]\n",
        "        price = dataset.data.iloc[idx][\"discounted_price\"]\n",
        "        link = dataset.data.iloc[idx][\"product_link\"]\n",
        "        about_review = dataset.data.iloc[idx][\"review_content\"]\n",
        "\n",
        "        product_text = f\"{product_name}. Category: {category}. Price: {price}. About Review: {about_review}\"\n",
        "        product_texts.append(product_text)\n",
        "        product_details.append((product_name, category, price, link))  # Storing details for results\n",
        "\n",
        "    # Compute embeddings for all product descriptions\n",
        "    product_embeddings = similarity_model.encode(product_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarities = util.pytorch_cos_sim(user_embedding, product_embeddings)[0]\n",
        "\n",
        "    # Get top N recommendations\n",
        "    top_indices = torch.argsort(similarities, descending=True)[:top_n]\n",
        "\n",
        "    recommendations = []\n",
        "    for idx in top_indices:\n",
        "        product_name, category, price, link = product_details[idx]\n",
        "        recommendations.append(\n",
        "            {\n",
        "                \"Product Name\": product_name,\n",
        "                \"Category\": category,\n",
        "                \"Price\": price,\n",
        "                \"Product Link\": link,\n",
        "                \"Similarity Score\": similarities[idx].item(),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Load dataset\n",
        "csv_path = \"/content/amazon.csv\"\n",
        "train_dataset = ProductDescriptionDataset(csv_path, TOKENIZER)\n",
        "\n",
        "# Load the YOLOv5 model (you can replace 'yolov5s' with your custom model)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "\n",
        "def display_results(user_description):\n",
        "    # Get recommended products\n",
        "    recommended_products = recommend_products(user_description, train_dataset, SIMILARITY_MODEL)\n",
        "\n",
        "    # Display recommendations\n",
        "    print(\"\\nTop Recommended Products:\")\n",
        "    for idx, product in enumerate(recommended_products, 1):\n",
        "        print(f\"\\n{idx}. {product['Product Name']}\")  # Fixed key name\n",
        "        print(f\"   - Category: {product['Category']}\")\n",
        "        print(f\"   - Price: {product['Price']}\")\n",
        "        print(f\"   - Link: {product['Product Link']}\")\n",
        "        print(f\"   - Similarity Score: {product['Similarity Score']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCcvrFrGCBFf",
        "outputId": "0439a6aa-11a4-4972-f5e6-53f3fed9713e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2025-2-22 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 model for object detection\n",
        "detector = YOLO(\"yolov8n.pt\")  # Using the smallest version for speed\n",
        "\n",
        "# Load BLIP model for image captioning\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def detect_products(image):\n",
        "    \"\"\"Detect products in the image using YOLOv8.\"\"\"\n",
        "    results = detector(image)\n",
        "    detected_objects = []\n",
        "\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            detected_objects.append((x1, y1, x2, y2))\n",
        "\n",
        "    return detected_objects\n",
        "\n",
        "def generate_caption(image):\n",
        "    \"\"\"Generate a product-focused description using BLIP.\"\"\"\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    output = caption_model.generate(**inputs)\n",
        "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "def process_image(image_path, output_path=\"output.jpg\"):\n",
        "    \"\"\"Process an image: detect products, draw bounding boxes, and generate captions.\"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Detect products\n",
        "    boxes = detect_products(image_np)\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    for x1, y1, x2, y2 in boxes:\n",
        "        cv2.rectangle(image_np, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Save processed image\n",
        "    output_image = Image.fromarray(image_np)\n",
        "    output_image.save(output_path)\n",
        "\n",
        "    # Generate and return product captions\n",
        "    captions = []\n",
        "    for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
        "        cropped_img = image.crop((x1, y1, x2, y2))\n",
        "        caption = generate_caption(cropped_img)\n",
        "        captions.append(f\"Product {i+1}: {caption}\")\n",
        "\n",
        "    return captions"
      ],
      "metadata": {
        "id": "Pm343EB1H8U1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input for product description\n",
        "user_input_type = input(\"Enter 1 for product description and 2 for image upload: \")\n",
        "if user_input_type == \"1\":\n",
        "    user_description = input(\"Enter Product Description: \")\n",
        "    display_results(user_description)\n",
        "else:\n",
        "    # Load an image (replace with your uploaded image)\n",
        "    img_path = input(\"Enter image path: \")\n",
        "    captions = process_image(img_path)\n",
        "    for caption in captions:\n",
        "        display_results(caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TinvfrGFDUR",
        "outputId": "2750e0fa-2ed5-4ed1-88ac-05496325ffe6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 for product description and 2 for image upload: 2\n",
            "Enter image path: /content/images.jpeg\n",
            "\n",
            "0: 320x640 1 bicycle, 72.4ms\n",
            "Speed: 2.6ms preprocess, 72.4ms inference, 6.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "Top Recommended Products:\n",
            "\n",
            "1. DIGITEKÂ® (DTR-200MT) (18 CM) Portable & Flexible Mini Tripod with Mobile Holder & 360 Degree Ball Head, For Smart Phones, Compact Cameras, GoPro, Maximum Operating Height: 7.87 Inch, Maximum Load Upto: 1 kgs\n",
            "   - Category: Electronics|Cameras&Photography|Accessories|Tripods&Monopods|TripodLegs\n",
            "   - Price: â‚¹349\n",
            "   - Link: https://www.amazon.in/DIGITEK-Portable-Flexible-Compact-Operating/dp/B08B6XWQ1C/ref=sr_1_269?qid=1672903008&s=computers&sr=1-269\n",
            "   - Similarity Score: 0.5415\n",
            "\n",
            "2. SYVO WT 3130 Aluminum Tripod (133CM), Universal Lightweight Tripod with Mobile Phone Holder Mount & Carry Bag for All Smart Phones, Gopro, Cameras - Brown\n",
            "   - Category: Electronics|Cameras&Photography|Accessories|Tripods&Monopods|Tabletop&TravelTripods\n",
            "   - Price: â‚¹799\n",
            "   - Link: https://www.amazon.in/Syvo-3130-Aluminum-Universal-Lightweight/dp/B07N42JB4S/ref=sr_1_49?qid=1672902997&s=computers&sr=1-49\n",
            "   - Similarity Score: 0.5333\n",
            "\n",
            "3. DIGITEKÂ® (DTR 260 GT) Gorilla Tripod/Mini 33 cm (13 Inch) Tripod for Mobile Phone with Phone Mount & Remote, Flexible Gorilla Stand for DSLR & Action Cameras\n",
            "   - Category: Electronics|Cameras&Photography|Accessories|Tripods&Monopods|TripodLegs\n",
            "   - Price: â‚¹399\n",
            "   - Link: https://www.amazon.in/DIGITEK%C2%AE-DTR-260-GT-Flexible/dp/B08LPJZSSW/ref=sr_1_59?qid=1672902997&s=computers&sr=1-59\n",
            "   - Similarity Score: 0.5223\n",
            "\n",
            "4. Digitek DTR 550 LW (67 Inch) Tripod For DSLR, Camera |Operating Height: 5.57 Feet | Maximum Load Capacity up to 4.5kg | Portable Lightweight Aluminum Tripod with 360 Degree Ball Head | Carry Bag Included (Black) (DTR 550LW)\n",
            "   - Category: Electronics|Cameras&Photography|Accessories|Tripods&Monopods|CompleteTripodUnits\n",
            "   - Price: â‚¹1,549\n",
            "   - Link: https://www.amazon.in/Digitek-DTR-550-LW-Tripod/dp/B074CWD7MS/ref=sr_1_124?qid=1672903001&s=computers&sr=1-124\n",
            "   - Similarity Score: 0.5063\n",
            "\n",
            "5. SLOVICÂ® Tripod Mount Adapter| Tripod Mobile Holder|Tripod Phone Mount(Made in India)| Smartphone Clip Clipper 360 Degree for Taking Magic Video Shots & Pictures.\n",
            "   - Category: Electronics|Cameras&Photography|Accessories|Tripods&Monopods|Tabletop&TravelTripods\n",
            "   - Price: â‚¹326\n",
            "   - Link: https://www.amazon.in/SLOVIC%C2%AE-Adapter-Smartphone-Clipper-Pictures/dp/B07RZZ1QSW/ref=sr_1_421?qid=1672903016&s=computers&sr=1-421\n",
            "   - Similarity Score: 0.5053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QUlhAOfMNJE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}